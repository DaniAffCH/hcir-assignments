{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "from facenet_pytorch import InceptionResnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "plt.ion()   # interactive mode\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "data_dir = 'data'\n",
    "image_datasets = datasets.ImageFolder(data_dir,data_transforms)\n",
    "\n",
    "dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
    "dataset_sizes = len(image_datasets) \n",
    "\n",
    "class_names = image_datasets.classes\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using \" + str(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dict(Counter(image_datasets.targets))\n",
    "\n",
    "names = list(image_datasets.classes)\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values, tick_label=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp  = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    inp  = std * inp + mean\n",
    "    inp  = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(5)  # pause a bit so that plots are updated\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            loss = loss.item() # detach gradient\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1) \n",
    "            corrects = torch.sum(preds == labels)\n",
    "\n",
    "            running_accuracy += corrects\n",
    "            running_loss += loss\n",
    "\n",
    "        running_loss /= dataset_sizes\n",
    "        running_accuracy /= dataset_sizes\n",
    "        print(f\"loss = {running_loss} accuracy = {running_accuracy}\")\n",
    "\n",
    "        if running_accuracy > best_acc:\n",
    "            best_acc = running_accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "loss = 0.4688713989590537 accuracy = 0.5356164574623108\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "loss = 0.4946634607823336 accuracy = 0.5479452013969421\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "loss = 0.4315396925051735 accuracy = 0.5794520974159241\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer_ft \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model_ft\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m exp_lr_scheduler \u001b[39m=\u001b[39m lr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer_ft, step_size\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                        num_epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrained_model.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSaving model \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mmodel_path)\n",
      "\u001b[1;32m/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniaffch/Desktop/Uni/Human_Robot/hcir-assignments/project/src/model/training.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m# detach gradient\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/sgd.py:151\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 151\u001b[0m sgd(params_with_grad,\n\u001b[1;32m    152\u001b[0m     d_p_list,\n\u001b[1;32m    153\u001b[0m     momentum_buffer_list,\n\u001b[1;32m    154\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    160\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    161\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    163\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/sgd.py:202\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 202\u001b[0m func(params,\n\u001b[1;32m    203\u001b[0m      d_p_list,\n\u001b[1;32m    204\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    205\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    206\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    207\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    208\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    209\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    210\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    211\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/sgd.py:238\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    236\u001b[0m     momentum_buffer_list[i] \u001b[39m=\u001b[39m buf\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     buf\u001b[39m.\u001b[39;49mmul_(momentum)\u001b[39m.\u001b[39madd_(d_p, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m dampening)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m nesterov:\n\u001b[1;32m    241\u001b[0m     d_p \u001b[39m=\u001b[39m d_p\u001b[39m.\u001b[39madd(buf, alpha\u001b[39m=\u001b[39mmomentum)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = InceptionResnetV1(pretrained='vggface2', device=device, classify= True, num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=40)\n",
    "\n",
    "model_path = \"trained_model.pt\"\n",
    "print(\"Saving model \"+model_path)\n",
    "torch.save(model_ft.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
