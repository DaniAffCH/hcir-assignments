{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Part\n",
    "\n",
    "1. Let us assume that a person is navigating through a busy railway station using a robotic\n",
    "wheelchair. How would you design this wheelchair such that there is high robot autonomy and\n",
    "high human control? (5%)\n",
    "\n",
    "For a possible scenario the wheelchair has some steering ability to direct the person away from risky and dangerous locations (such as the train tracks) at the railway station. The wheelchair has sensors in order to detect the white lines which should not be crossed and slows down in case the person is getting too close to dangerous areas like that. Furthermore, the wheelchair can send virbrations at the hand rest or make noises to inform the person about a risky sitation or upcoming locations. By those abilities the robot has a quite high level of autonomy because he can inform its user and also suggest/initiate steering directions. This could be a level 9 in the One Dimensional view of Autonomy. Moreover, the wheelchair could help the person to find a lift to get to the tracks by showing routes on a display so that stairs can be avoided.<br>\n",
    "On the other side the human can always not accept the robots steering suggestions and steer elsewhere. Therefore, the human has always greater power with his/her steering and stopping and the human's actions will always have priority before the robots suggestions. Whenever the robot suggest something, but the person wants to do something else, the wheelchair will always accept the persons wish. This decision shows that the human still has full control over the wheel chair even though the robot can steer and decide for possible action on its own. Also the human can turn of the suggestions and recommondations individually. The other way around it is not possible. <br>\n",
    "The best case would therefore be that the human can work together with the wheelchair. The wheelchair is a supporting component so that both collaborate on the same goal for the person to have a safe and comfortable ride through the busy railway station. One could compare my example with modern cars nowadays who slow down in case some car is in front of the driver but still the driver can decide whether to actually slow down.\n",
    "\n",
    "\n",
    "1. Answer the following questions:\n",
    "a. In the ethno-socio-linguistic model of communication, there are no speakers or listeners,\n",
    "but just interpreters. Why is this so? (5%)\n",
    "\n",
    "This model emphazises that we always communicate - intentional or not. Even if we do not intentionally express, others are always interpreting us. Every person always expresses themselves and interprets communication signs from others. Different codes can be used such as linusitc, discursive, social culturla and psyhcologic. Different parameters such as the context or metacommunication play also a important role for the interpretation. The context can be temproal, spatial, sociaio-cultural (with whom) and others (obejcts or audience). Moreover, the same messages can have different meanings in different contexts. There can also be metacommmunication which is communication about communicating for example by clarifying certain things. Inerpreters always interpret each other's signs and construct them together to meanings. So, this model concentrates on the continuous interpretation of each other because it stresses out that speakers and listeners are always interpeters at the same time who express and send signals during a conversation.\n",
    "\n",
    "b. Explain how the interpreters co-construct the meaning of a conversation. (5%)\n",
    "\n",
    "As alreasy mentioned there are different aspsects that are influence the interpretation process. Influenced through the context, differently used codes of each interpreter and metacommunication can have an affect on the interpreters process of constructing a meaning. Both sender and reciever decide about how a conversation goes and certrain aspects such as duration, topic and depth of details of a conversation. Through the different signs and with the help of metacommunication both interpreter want to conclude to the same meaning in order to avoid miscommunicating. Every person is different which also means that every person interprets and express differently. Thereby interrupting a conversation to metacommunicate can help to co-construct a meaning. One has to understand the other in order to refer to the same thing and understand each other to co-construct a meaning together. \n",
    "\n",
    "1. Write a script for a conversation between a human and a service robot in a restaurant setting.\n",
    "The robot is supposed to take orders from the human and deliver the requested food and drinks.\n",
    "During the design of the script, include any THREE of the following concepts associated with\n",
    "verbal communication and highlight how you included it in the script (20%):<br>\n",
    "i. Turn-taking<br>\n",
    "ii. Backchanneling<br>\n",
    "iii. Metacommunication<br>\n",
    "iv. Symbol grounding<br>\n",
    "\n",
    "For exam preparation I take all 4: \n",
    "\n",
    "Human: Wellcome, what would you like to drink and eat today? (TURN-TAKING) <br>\n",
    "Robot: Hello, I want to drink a tea. (TURN-TAKING)<br>\n",
    "Human: Okay, you want to drink a tea. I will get you an ice tea. Anything else? (TURN-TAKING...)<br>\n",
    "Robot: Sorry, I heard you were bringing me a an iced tea. (BACKCHANNELING) I want a tea.<br>\n",
    "Human: Oh, we have different tees. We have ice tea and hot tea. <br>\n",
    "Robot: I might have misunderstood you. What is ice tea? (METACOMMUNICATION)<br>\n",
    "Human: An ice tea is a cold and sweet tea drink. Do you want that?<br>\n",
    "Robot: Yes thank you and I want fries.<br>\n",
    "Human: Alright, should I pass you the salt for them?<br>\n",
    "Robot: So you mean the salt to salten food to eat, right? (SYMBOL GROUNDING)<br>\n",
    "Human: Correct, normal table salt.\n",
    "\n",
    "\n",
    "1. How would you apply the TAMER framework to enable a human to teach a robotic wheelchair to\n",
    "drive up a ramp on its own? (10%)\n",
    "\n",
    "By driving up the ramp the human will push a greent button on the wheelchair in order to signalize the wheelchair when the ramp has been passed successfully. This would be a positive reward (R+). Pushing the green button is the delyaed feedback variable h in our discussed TAMER framework of the lecture. The Human evaluative feedback about the quality of the agent’s action is mapped to a numeric reward. Through sensors the wheelchair can detect whenever there is a ramp and when it ends. Therefore it can identify different states of the environment which are passed to the Action selector and Credit assigner. The action selecter passes the action alpha of driving up the ramp to the credit assigner which takes the alpha, the detected state s and the delayed feedback h and models the delayed feedback. After that is the feedback to the Supervised Reward Learner. The Supervised Reward Learner learns the human's (re-inforcement) function H : S × A. This is communicated to the Action Selector for mypopic rewards in order to learn long term and improve for the next ramp. \n",
    "\n",
    "1. Name any two non-verbal signals of communication and give an example of how each of these\n",
    "signals could help in making human-robot interaction more intuitive. (5%)\n",
    "\n",
    "The first one would be facial expressions. For example if a person smiles, that is a positive feedback or impression to the reciever/communication partner. For Human-Robot interactions this could help whenever a robot has to talk to people in a morpholical context. One scenario could be a robot helping pre-school children to train their vocabulary. When talking with children and giving them feedback, the robot needs to make a harmless impression to the children. Whenever talking to them it might help to smile in order to signalize a nice and friendly behavior. This could make the overall interaction and covnersation more intuitive, natrual and comftable for the children. \n",
    "\n",
    "Another example is the gaze. A gaze can signalize many different things such as intent, emotion or interest. In a similiar example like before: when a robot talks to a person it is helpful it keeps looking at the person when it listens. Also when starting to speak it is important to look a the reciever/communication partner so that he/she knows who the other is talking to. The same goes for the robot in that case. Keeping eye contact for a certain time can help to make the overall communication more intuitive and can avoid misunderstandings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Programming tasks (30%)\n",
    "1. Implement a given bayesian network using pyagrum library. The conditional probability table will\n",
    "be provided. After this, make inferences for the given queries? (10%)\n",
    "1. Given a dataset, apply normality test and then t-tests to validate a given hypothesis. Use\n",
    "statsmodel, pandas, et"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
